{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import sys\n",
      "sys.path.append('/home/karthikeya/svn/repo/lib/pysgpp')\n",
      "sys.path.append('/home/karthikeya/MachineLearning/elastic_ml/pyoptim')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from wrappers import SparseGridWrapper\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import matplotlib.pylab as pl\n",
      "import seaborn as sns\n",
      "from pysgpp import *\n",
      "import scipy.io.arff as arff\n",
      "from algorithms import vSGD, SGD, vSGDfd, AnnealingSGD, AveragingSGD"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_mse(s, y, mult_eval):\n",
      "    if s.provider._counter % 10 == 0:\n",
      "        params_DV = DataVector(s.bestParameters)\n",
      "        results_DV = DataVector(len(y))\n",
      "        mult_eval.mult(params_DV, results_DV);\n",
      "        #print y[:15]\n",
      "        #print results_DV.array()[:15]\n",
      "        residual = np.linalg.norm(y - results_DV.array())\n",
      "        print \"Itearation %d, learning rate %f, train MSE %e\" \\\n",
      "        %(s.provider._counter, np.mean(s.learning_rate), residual**2/len(y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim = 1\n",
      "level = 4\n",
      "l = 1E-8\n",
      "grid = Grid.createLinearGrid(dim)\n",
      "gridStorage = grid.getStorage()\n",
      "gridGen = grid.createGridGenerator()\n",
      "gridGen.regular(level)\n",
      "\n",
      "size = 1000\n",
      "x = np.random.rand(size*dim).reshape(size,-1)\n",
      "#y = np.apply_along_axis(lambda p:4*p[0]*(1-p[0])*p[1]*(1-p[1]), 1, x)\n",
      "y = np.apply_along_axis(lambda p:4*p[0]*(1-p[0]), 1, x)\n",
      "dataset = np.vstack([x.T,y]).T\n",
      "\n",
      "\n",
      "\n",
      "data_matrix = DataMatrix(dataset[:,:dim])\n",
      "print data_matrix.getNcols()\n",
      "mult_eval = createOperationMultipleEval(grid, data_matrix);\n",
      "print_cb = lambda s: print_mse(s, dataset[:,dim], mult_eval)\n",
      " \n",
      "f = SparseGridWrapper(grid, dataset, l)\n",
      "x0 = np.zeros(grid.getSize())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.reset()\n",
      "algo = vSGDfd(f, x0, callback=print_cb, loss_target=-np.inf, init_samples=1, batch_size=10)\n",
      "algo.run(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Itearation 10, learning rate 0.048273, train MSE 5.401508e-01\n",
        "Itearation 20, learning rate 0.199367, train MSE 3.470608e-01\n",
        "Itearation 30, learning rate 0.218098, train MSE 1.262472e-01\n",
        "Itearation 40, learning rate 0.213137, train MSE 2.483999e-02\n",
        "Itearation 50, learning rate 0.206024, train MSE 8.376106e-03\n",
        "Itearation 60, learning rate 0.195053, train MSE 3.109963e-03\n",
        "Itearation 70, learning rate 0.178632, train MSE 1.498833e-03\n",
        "Itearation 80, learning rate 0.157239, train MSE 7.803031e-04\n",
        "Itearation 90, learning rate 0.147253, train MSE 5.199885e-04\n",
        "Itearation 100, learning rate 0.132116, train MSE 4.061937e-04\n",
        "Itearation 110, learning rate 0.123226, train MSE 3.038994e-04\n",
        "Itearation 120, learning rate 0.111126, train MSE 2.589865e-04\n",
        "Itearation 130, learning rate 0.101308, train MSE 2.342992e-04\n",
        "Itearation 140, learning rate 0.102097, train MSE 2.059303e-04\n",
        "Itearation 150, learning rate 0.097924, train MSE 1.908707e-04\n",
        "Itearation 160, learning rate 0.110754, train MSE 1.616926e-04\n",
        "Itearation 170, learning rate 0.106495, train MSE 1.483574e-04\n",
        "Itearation 180, learning rate 0.110004, train MSE 1.366954e-04\n",
        "Itearation 190, learning rate 0.113810, train MSE 1.271857e-04\n",
        "Itearation 200, learning rate 0.112894, train MSE 1.194462e-04\n",
        "Itearation 210, learning rate 0.121400, train MSE 1.115599e-04\n",
        "Itearation 220, learning rate 0.090366, train MSE 1.122348e-04\n",
        "Itearation 230, learning rate 0.091319, train MSE 1.103485e-04\n",
        "Itearation 240, learning rate 0.108439, train MSE 1.020706e-04"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Itearation 250, learning rate 0.098920, train MSE 9.805640e-05\n",
        "Itearation 260, learning rate 0.077301, train MSE 9.517748e-05\n",
        "Itearation 270, learning rate 0.108015, train MSE 8.403583e-05\n",
        "Itearation 280, learning rate 0.117215, train MSE 7.819306e-05\n",
        "Itearation 290, learning rate 0.118080, train MSE 7.256736e-05\n",
        "Itearation 300, learning rate 0.145870, train MSE 6.752971e-05\n",
        "Itearation 310, learning rate 0.148519, train MSE 6.383746e-05\n",
        "Itearation 320, learning rate 0.129635, train MSE 6.218171e-05\n",
        "Itearation 330, learning rate 0.136188, train MSE 6.017428e-05\n",
        "Itearation 340, learning rate 0.139299, train MSE 5.683657e-05\n",
        "Itearation 350, learning rate 0.133485, train MSE 5.397863e-05\n",
        "Itearation 360, learning rate 0.136959, train MSE 5.194908e-05\n",
        "Itearation 370, learning rate 0.132524, train MSE 5.015692e-05\n",
        "Itearation 380, learning rate 0.121428, train MSE 4.944714e-05\n",
        "Itearation 390, learning rate 0.119067, train MSE 4.817903e-05\n",
        "Itearation 400, learning rate 0.116857, train MSE 4.754974e-05\n",
        "Itearation 410, learning rate 0.120690, train MSE 4.550254e-05\n",
        "Itearation 420, learning rate 0.132228, train MSE 4.475748e-05\n",
        "Itearation 430, learning rate 0.141421, train MSE 4.368846e-05\n",
        "Itearation 440, learning rate 0.146257, train MSE 4.316714e-05\n",
        "Itearation 450, learning rate 0.132712, train MSE 4.226003e-05\n",
        "Itearation 460, learning rate 0.126748, train MSE 4.097124e-05\n",
        "Itearation 470, learning rate 0.133120, train MSE 4.016956e-05\n",
        "Itearation 480, learning rate 0.094340, train MSE 3.997921e-05\n",
        "Itearation 490, learning rate 0.103303, train MSE 3.928861e-05\n",
        "Itearation 500, learning rate 0.103639, train MSE 3.856829e-05\n",
        "Itearation 510, learning rate 0.094353, train MSE 3.814805e-05\n",
        "Itearation 520, learning rate 0.087215, train MSE 3.774375e-05\n",
        "Itearation 530, learning rate 0.091533, train MSE 3.725083e-05\n",
        "Itearation 540, learning rate 0.084968, train MSE 3.698293e-05\n",
        "Itearation 550, learning rate 0.112036, train MSE 3.627838e-05"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Itearation 560, learning rate 0.121071, train MSE 3.573038e-05\n",
        "Itearation 570, learning rate 0.115522, train MSE 3.546382e-05\n",
        "Itearation 580, learning rate 0.107982, train MSE 3.501694e-05\n",
        "Itearation 590, learning rate 0.116026, train MSE 3.466680e-05\n",
        "Itearation 600, learning rate 0.096722, train MSE 3.454311e-05\n",
        "Itearation 610, learning rate 0.103197, train MSE 3.440538e-05\n",
        "Itearation 620, learning rate 0.117957, train MSE 3.394954e-05\n",
        "Itearation 630, learning rate 0.103250, train MSE 3.380054e-05\n",
        "Itearation 640, learning rate 0.113516, train MSE 3.355236e-05\n",
        "Itearation 650, learning rate 0.084718, train MSE 3.354709e-05\n",
        "Itearation 660, learning rate 0.104771, train MSE 3.343760e-05\n",
        "Itearation 670, learning rate 0.086761, train MSE 3.339404e-05\n",
        "Itearation 680, learning rate 0.087465, train MSE 3.324598e-05\n",
        "Itearation 690, learning rate 0.071706, train MSE 3.320009e-05\n",
        "Itearation 700, learning rate 0.077577, train MSE 3.307581e-05\n",
        "Itearation 710, learning rate 0.079157, train MSE 3.300873e-05\n",
        "Itearation 720, learning rate 0.084990, train MSE 3.291844e-05\n",
        "Itearation 730, learning rate 0.091555, train MSE 3.282523e-05\n",
        "Itearation 740, learning rate 0.090022, train MSE 3.269934e-05\n",
        "Itearation 750, learning rate 0.086851, train MSE 3.257181e-05\n",
        "Itearation 760, learning rate 0.118101, train MSE 3.234454e-05\n",
        "Itearation 770, learning rate 0.116261, train MSE 3.225379e-05\n",
        "Itearation 780, learning rate 0.117959, train MSE 3.215635e-05\n",
        "Itearation 790, learning rate 0.097515, train MSE 3.212722e-05\n",
        "Itearation 800, learning rate 0.066395, train MSE 3.212366e-05\n",
        "Itearation 810, learning rate 0.057926, train MSE 3.209678e-05\n",
        "Itearation 820, learning rate 0.088203, train MSE 3.190948e-05\n",
        "Itearation 830, learning rate 0.095410, train MSE 3.186427e-05\n",
        "Itearation 840, learning rate 0.129350, train MSE 3.174287e-05"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Itearation 850, learning rate 0.132004, train MSE 3.168262e-05\n",
        "Itearation 860, learning rate 0.107795, train MSE 3.168012e-05\n",
        "Itearation 870, learning rate 0.084229, train MSE 3.164999e-05\n",
        "Itearation 880, learning rate 0.110280, train MSE 3.158266e-05\n",
        "Itearation 890, learning rate 0.094717, train MSE 3.157374e-05\n",
        "Itearation 900, learning rate 0.088696, train MSE 3.153783e-05\n",
        "Itearation 910, learning rate 0.059225, train MSE 3.152067e-05\n",
        "Itearation 920, learning rate 0.055925, train MSE 3.150411e-05\n",
        "Itearation 930, learning rate 0.053685, train MSE 3.148448e-05\n",
        "Itearation 940, learning rate 0.044913, train MSE 3.147047e-05\n",
        "Itearation 950, learning rate 0.047886, train MSE 3.145041e-05\n",
        "Itearation 960, learning rate 0.038299, train MSE 3.144532e-05\n",
        "Itearation 970, learning rate 0.054806, train MSE 3.142003e-05\n",
        "Itearation 980, learning rate 0.069948, train MSE 3.138305e-05\n",
        "Itearation 990, learning rate 0.080107, train MSE 3.133124e-05\n",
        "Itearation 1000, learning rate 0.063845, train MSE 3.131430e-05\n",
        "Itearation 1010, learning rate 0.072854, train MSE 3.129081e-05\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.reset()\n",
      "algo = vSGD(f, x0, callback=print_cb, loss_target=-np.inf, init_samples=1, batch_size=1)\n",
      "algo.run(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Itearation 10, learning rate 1.160830, train MSE 6.632041e-01\n",
        "Itearation 20, learning rate 0.733291, train MSE 1.040084e+00\n",
        "Itearation 30, learning rate 1.352741, train MSE 2.951414e-01\n",
        "Itearation 40, learning rate 0.304476, train MSE 2.592388e-01\n",
        "Itearation 50, learning rate 0.266087, train MSE 2.376861e-01\n",
        "Itearation 60, learning rate 0.281802, train MSE 1.385722e-01\n",
        "Itearation 70, learning rate 0.289324, train MSE 1.219562e-01\n",
        "Itearation 80, learning rate 0.226809, train MSE 1.173140e-01\n",
        "Itearation 90, learning rate 0.163870, train MSE 1.222729e-01\n",
        "Itearation 100, learning rate 0.150594, train MSE 1.067859e-01\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.reset()\n",
      "algo = vSGD(f, x0, callback=print_cb, loss_target=-np.inf, init_samples=1, batch_size=10)\n",
      "algo.run(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Itearation 10, learning rate 1.901259, train MSE 5.401508e-01\n",
        "Itearation 20, learning rate 38.305925, train MSE 1.539422e+00\n",
        "Itearation 30, learning rate 23.412923, train MSE 1.139168e+00\n",
        "Itearation 40, learning rate 3.006407, train MSE 2.577604e+00\n",
        "Itearation 50, learning rate 2.644808, train MSE 2.018853e+00\n",
        "Itearation 60, learning rate 2.453294, train MSE 3.912087e+00\n",
        "Itearation 70, learning rate 1.425913, train MSE 3.744568e+00\n",
        "Itearation 80, learning rate 1.996406, train MSE 2.258052e+00\n",
        "Itearation 90, learning rate 1.740599, train MSE 2.101232e+00\n",
        "Itearation 100, learning rate 1.895978, train MSE 1.256192e+00\n",
        "Itearation 110, learning rate 1.537163, train MSE 5.972494e-01\n",
        "Itearation 120, learning rate 1.461274, train MSE 4.692753e-01\n",
        "Itearation 130, learning rate 1.404958, train MSE 3.444223e-01\n",
        "Itearation 140, learning rate 1.508167, train MSE 2.997607e-01\n",
        "Itearation 150, learning rate 1.523088, train MSE 3.022343e-01\n",
        "Itearation 160, learning rate 1.438261, train MSE 3.021013e-01\n",
        "Itearation 170, learning rate 1.369847, train MSE 3.053048e-01\n",
        "Itearation 180, learning rate 1.375716, train MSE 2.212237e-01\n",
        "Itearation 190, learning rate 1.247705, train MSE 2.202779e-01\n",
        "Itearation 200, learning rate 1.026203, train MSE 2.168950e-01\n",
        "Itearation 210, learning rate 1.025315, train MSE 1.827310e-01\n",
        "Itearation 220, learning rate 1.050535, train MSE 1.612406e-01\n",
        "Itearation 230, learning rate 0.979357, train MSE 1.602649e-01\n",
        "Itearation 240, learning rate 0.996897, train MSE 1.442157e-01\n",
        "Itearation 250, learning rate 0.948029, train MSE 1.418065e-01"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Itearation 260, learning rate 0.781722, train MSE 1.352341e-01\n",
        "Itearation 270, learning rate 0.762370, train MSE 1.339530e-01\n",
        "Itearation 280, learning rate 0.639635, train MSE 1.191676e-01\n",
        "Itearation 290, learning rate 0.638398, train MSE 1.164091e-01\n",
        "Itearation 300, learning rate 0.628931, train MSE 1.117108e-01\n",
        "Itearation 310, learning rate 0.682360, train MSE 1.050373e-01\n",
        "Itearation 320, learning rate 0.762734, train MSE 9.846469e-02\n",
        "Itearation 330, learning rate 0.747601, train MSE 9.852560e-02\n",
        "Itearation 340, learning rate 0.761276, train MSE 9.310708e-02\n",
        "Itearation 350, learning rate 0.768979, train MSE 8.911165e-02\n",
        "Itearation 360, learning rate 0.787436, train MSE 8.846489e-02\n",
        "Itearation 370, learning rate 0.829173, train MSE 8.630234e-02\n",
        "Itearation 380, learning rate 0.809242, train MSE 8.610648e-02\n",
        "Itearation 390, learning rate 0.789709, train MSE 8.653092e-02\n",
        "Itearation 400, learning rate 0.812696, train MSE 7.533749e-02\n",
        "Itearation 410, learning rate 0.847350, train MSE 4.795559e-02\n",
        "Itearation 420, learning rate 0.838794, train MSE 4.736729e-02\n",
        "Itearation 430, learning rate 0.820093, train MSE 4.483480e-02\n",
        "Itearation 440, learning rate 0.810515, train MSE 4.480532e-02\n",
        "Itearation 450, learning rate 0.770721, train MSE 4.286023e-02\n",
        "Itearation 460, learning rate 0.804700, train MSE 4.094283e-02\n",
        "Itearation 470, learning rate 0.739143, train MSE 4.082721e-02\n",
        "Itearation 480, learning rate 0.713618, train MSE 3.881034e-02\n",
        "Itearation 490, learning rate 0.771013, train MSE 3.834636e-02\n",
        "Itearation 500, learning rate 0.788745, train MSE 3.825532e-02\n",
        "Itearation 510, learning rate 0.791067, train MSE 3.751690e-02\n",
        "Itearation 520, learning rate 0.677088, train MSE 3.743931e-02\n",
        "Itearation 530, learning rate 0.742918, train MSE 3.680966e-02\n",
        "Itearation 540, learning rate 0.764981, train MSE 3.545086e-02\n",
        "Itearation 550, learning rate 0.732791, train MSE 3.558442e-02\n",
        "Itearation 560, learning rate 0.704449, train MSE 3.477682e-02\n",
        "Itearation 570, learning rate 0.727246, train MSE 3.231554e-02\n",
        "Itearation 580, learning rate 0.700018, train MSE 3.159307e-02\n",
        "Itearation 590, learning rate 0.667851, train MSE 3.174088e-02\n",
        "Itearation 600, learning rate 0.667556, train MSE 3.169357e-02"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Itearation 610, learning rate 0.629736, train MSE 3.032662e-02\n",
        "Itearation 620, learning rate 0.665812, train MSE 3.057856e-02\n",
        "Itearation 630, learning rate 0.642647, train MSE 2.985066e-02\n",
        "Itearation 640, learning rate 0.399944, train MSE 2.975099e-02\n",
        "Itearation 650, learning rate 0.369555, train MSE 2.937298e-02\n",
        "Itearation 660, learning rate 0.399793, train MSE 2.884839e-02\n",
        "Itearation 670, learning rate 0.382449, train MSE 2.823683e-02\n",
        "Itearation 680, learning rate 0.379652, train MSE 2.800580e-02\n",
        "Itearation 690, learning rate 0.391693, train MSE 2.753794e-02\n",
        "Itearation 700, learning rate 0.372448, train MSE 2.758051e-02\n",
        "Itearation 710, learning rate 0.367972, train MSE 2.744811e-02\n",
        "Itearation 720, learning rate 0.376409, train MSE 2.722128e-02\n",
        "Itearation 730, learning rate 0.372368, train MSE 2.683079e-02\n",
        "Itearation 740, learning rate 0.390433, train MSE 2.669936e-02\n",
        "Itearation 750, learning rate 0.384279, train MSE 2.574386e-02\n",
        "Itearation 760, learning rate 0.408207, train MSE 2.574259e-02\n",
        "Itearation 770, learning rate 0.420006, train MSE 2.524347e-02\n",
        "Itearation 780, learning rate 0.466356, train MSE 2.509822e-02\n",
        "Itearation 790, learning rate 0.480164, train MSE 2.442938e-02\n",
        "Itearation 800, learning rate 0.514623, train MSE 2.419359e-02\n",
        "Itearation 810, learning rate 0.505061, train MSE 2.387203e-02\n",
        "Itearation 820, learning rate 0.519644, train MSE 2.297549e-02\n",
        "Itearation 830, learning rate 0.512349, train MSE 2.281596e-02\n",
        "Itearation 840, learning rate 0.483642, train MSE 2.227725e-02\n",
        "Itearation 850, learning rate 0.483228, train MSE 2.211715e-02\n",
        "Itearation 860, learning rate 0.511831, train MSE 2.100569e-02\n",
        "Itearation 870, learning rate 0.495024, train MSE 2.083607e-02\n",
        "Itearation 880, learning rate 0.517001, train MSE 1.891614e-02\n",
        "Itearation 890, learning rate 0.532257, train MSE 1.848411e-02\n",
        "Itearation 900, learning rate 0.549177, train MSE 1.807296e-02\n",
        "Itearation 910, learning rate 0.534223, train MSE 1.741155e-02\n",
        "Itearation 920, learning rate 0.543270, train MSE 1.716405e-02\n",
        "Itearation 930, learning rate 0.545438, train MSE 1.706896e-02"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Itearation 940, learning rate 0.562653, train MSE 1.565640e-02\n",
        "Itearation 950, learning rate 0.523219, train MSE 1.547893e-02\n",
        "Itearation 960, learning rate 0.551341, train MSE 1.543267e-02\n",
        "Itearation 970, learning rate 0.619794, train MSE 1.531893e-02\n",
        "Itearation 980, learning rate 0.675339, train MSE 1.482565e-02\n",
        "Itearation 990, learning rate 0.701778, train MSE 1.469636e-02\n",
        "Itearation 1000, learning rate 0.698498, train MSE 1.449313e-02\n",
        "Itearation 1010, learning rate 0.660390, train MSE 1.415427e-02\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collect_mse(s, y, collection, mult_eval):\n",
      "    if s.provider._counter % 10 == 0:\n",
      "        params_DV = DataVector(s.bestParameters)\n",
      "        results_DV = DataVector(len(y))\n",
      "        mult_eval.mult(params_DV, results_DV);\n",
      "        #print y[:15]\n",
      "        #print results_DV.array()[:15]\n",
      "        residual = np.linalg.norm(y - results_DV.array())\n",
      "        collection.append([s.provider._counter, np.mean(s.learning_rate), residual**2/len(y)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dim = 2\n",
      "level = 4\n",
      "l = 1E-8\n",
      "grid = Grid.createLinearGrid(dim)\n",
      "gridStorage = grid.getStorage()\n",
      "gridGen = grid.createGridGenerator()\n",
      "gridGen.regular(level)\n",
      "\n",
      "size = 1000\n",
      "x = np.random.rand(size*dim).reshape(size,-1)\n",
      "y = np.apply_along_axis(lambda p:4*p[0]*(1-p[0])*p[1]*(1-p[1]), 1, x)\n",
      "dataset = np.vstack([x.T,y]).T\n",
      "\n",
      "\n",
      "data_matrix = DataMatrix(dataset[:,:dim])\n",
      "mult_eval = createOperationMultipleEval(grid, data_matrix);\n",
      "\n",
      " \n",
      "f = SparseGridWrapper(grid, dataset, l)\n",
      "x0 = np.zeros(grid.getSize())\n",
      "#algo = SGD(f, x0, callback=print_cb, learning_rate=0.2, loss_target=-np.inf)\n",
      "\n",
      "#algo = vSGD(f, x0, callback=print_cb, loss_target=-np.inf, init_samples=10, batch_size=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collect_fd = []\n",
      "collect_cb = lambda s: collect_mse(s, dataset[:,dim], collect_fd, mult_eval)\n",
      "f.reset()\n",
      "algo = vSGDfd(f, x0, callback=collect_cb, loss_target=-np.inf, init_samples=5, batch_size=10)\n",
      "algo.run(1000)\n",
      "collect_fd = np.array(collect_fd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}